{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5749de22",
   "metadata": {},
   "source": [
    "# Triton Kernel Profiling on NVIDIA GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071f48c",
   "metadata": {},
   "source": [
    "## Check Nsight Tools Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b2e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.1.1.0 (build 35528883) (public-release)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n"
     ]
    }
   ],
   "source": [
    "!ncu --version\n",
    "!nsys --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2fe9b7",
   "metadata": {},
   "source": [
    "## Check profiling environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aca1884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp counter supported: Yes\n",
      "\n",
      "CPU Profiling Environment Check\n",
      "Root privilege: enabled\n",
      "Linux Kernel Paranoid Level = 2\n",
      "Linux Distribution = CentOS\n",
      "Linux Kernel Version = 6.15.4-200.fc42.x86_64: OK\n",
      "Linux perf_event_open syscall available: OK\n",
      "Sampling trigger event available: OK\n",
      "Intel(c) Last Branch Record support: Available\n",
      "CPU Profiling Environment (process-tree): OK\n",
      "CPU Profiling Environment (system-wide): OK\n",
      "\n",
      "See the product documentation at https://docs.nvidia.com/nsight-systems for more information,\n",
      "including information on how to set the Linux Kernel Paranoid Level.\n"
     ]
    }
   ],
   "source": [
    "!nsys status -e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae93301",
   "metadata": {},
   "source": [
    "## Python code for the bad MatMul kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425df7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bad_matmul.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  bad_matmul.py\n",
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "\n",
    "def is_cuda():\n",
    "    return triton.runtime.driver.active.get_current_target().backend == \"cuda\"\n",
    "\n",
    "\n",
    "# Triton Autotuning Configs for NVIDIA\n",
    "def get_autotune_config():\n",
    "    return [\n",
    "        # Bad config\n",
    "        triton.Config({'BLOCK_SIZE_M': 16, 'BLOCK_SIZE_N': 16, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 1}, num_stages=3,\n",
    "                      num_warps=1),\n",
    "    ]\n",
    "\n",
    "\n",
    "# MatMul kernel\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,\n",
    "        stride_bk, stride_bn,\n",
    "        stride_cm, stride_cn,\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        accumulator = tl.dot(a, b, accumulator)\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "# MatMul kernel wrapper function\n",
    "def matmul(a, b):\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel[grid](\n",
    "        a, b, c,\n",
    "        M, N, K,\n",
    "        a.stride(0), a.stride(1),\n",
    "        b.stride(0), b.stride(1),\n",
    "        c.stride(0), c.stride(1),\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test matrices\n",
    "    torch.manual_seed(0)\n",
    "    M = 4096\n",
    "    N = 4096\n",
    "    a = torch.randn((M, N), device='cuda', dtype=torch.float16)\n",
    "    b = torch.randn((N, M), device='cuda', dtype=torch.float16)\n",
    "\n",
    "    # Run the MatMul kernel\n",
    "    triton_output = matmul(a, b)\n",
    "    print(f\"triton_output_with_fp16_inputs={triton_output}\")\n",
    "\n",
    "    # Run the Torch MatMul kernel for comparison\n",
    "    torch_output = torch.matmul(a, b)\n",
    "    print(f\"torch_output_with_fp16_inputs={torch_output}\")\n",
    "\n",
    "    # Verify the Triton kernels results against the Torch kernels\n",
    "    triton.testing.assert_close(triton_output, torch_output, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbdef61",
   "metadata": {},
   "source": [
    "## Let's profile the bad kernel with Nsight Compute and generate a report file (bad_matmul.ncu-rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de54b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 20299 (/usr/bin/python3.12)\n",
      "==PROF== Profiling \"distribution_elementwise_grid...\" - 0: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"distribution_elementwise_grid...\" - 1: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 2: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 3: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 4: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 5: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 6: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 7: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 8: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 9: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 10: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 11: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 12: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 13: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 14: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 15: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceReduceSingleTileKernel\" - 16: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceCompactInitKernel\" - 17: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceSelectSweepKernel\" - 18: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"index_elementwise_kernel\" - 19: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 20: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 21: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 22: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 23: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 24: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 25: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 26: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 27: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 28: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 29: 0%....50%....100% - 40 passes\n",
      "triton_output_with_fp16_inputs=tensor([[ -90.1875,   23.7188,    4.5820,  ...,   45.5312,   99.7500,\n",
      "          -18.7656],\n",
      "        [  50.1562,  -74.5000,    7.1836,  ...,  -65.9375,   12.8828,\n",
      "           11.8906],\n",
      "        [ -70.3750,   73.3125,   16.3438,  ...,   46.4062,   91.8125,\n",
      "           67.3750],\n",
      "        ...,\n",
      "        [-111.3125,  -90.3125,   -7.9844,  ...,   16.4375,   77.3125,\n",
      "          -47.7812],\n",
      "        [  43.5938,   13.3594,  -18.0156,  ...,  -19.0156,    0.4849,\n",
      "          -19.2812],\n",
      "        [  -7.6992,   53.0000,   74.5625,  ...,    4.3945,   17.4375,\n",
      "           30.4531]], device='cuda:0', dtype=torch.float16)\n",
      "==PROF== Profiling \"Kernel2\" - 30: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 31: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 32: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 33: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 34: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 35: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 36: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 37: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 38: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 39: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 40: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 41: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 42: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 43: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceReduceSingleTileKernel\" - 44: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceCompactInitKernel\" - 45: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceSelectSweepKernel\" - 46: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"index_elementwise_kernel\" - 47: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 48: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 49: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 50: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 51: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 52: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 53: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 54: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 55: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 56: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 57: 0%....50%....100% - 40 passes\n",
      "torch_output_with_fp16_inputs=tensor([[ -90.1875,   23.7188,    4.5820,  ...,   45.5312,   99.7500,\n",
      "          -18.7656],\n",
      "        [  50.1562,  -74.5000,    7.1836,  ...,  -65.9375,   12.8828,\n",
      "           11.8906],\n",
      "        [ -70.3750,   73.3125,   16.3438,  ...,   46.4062,   91.8125,\n",
      "           67.3750],\n",
      "        ...,\n",
      "        [-111.3125,  -90.3125,   -7.9844,  ...,   16.4375,   77.3125,\n",
      "          -47.7812],\n",
      "        [  43.5938,   13.3594,  -18.0156,  ...,  -19.0156,    0.4849,\n",
      "          -19.2812],\n",
      "        [  -7.6992,   53.0000,   74.5625,  ...,    4.3945,   17.4375,\n",
      "           30.4531]], device='cuda:0', dtype=torch.float16)\n",
      "==PROF== Disconnected from process 20299\n",
      "==PROF== Report: /workspace/bad_matmul.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "!ncu --target-processes all --set full --import-source on -f -o bad_matmul python3.12 bad_matmul.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a4161",
   "metadata": {},
   "source": [
    "## Python code for an improved MatMul kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4cde5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing improved_matmul.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  improved_matmul.py\n",
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "\n",
    "def is_cuda():\n",
    "    return triton.runtime.driver.active.get_current_target().backend == \"cuda\"\n",
    "\n",
    "\n",
    "# Triton Autotuning Configs for NVIDIA\n",
    "def get_autotune_config():\n",
    "    return [\n",
    "        # Good configs\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5,\n",
    "                      num_warps=2),\n",
    "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5,\n",
    "                      num_warps=2),\n",
    "    ]\n",
    "\n",
    "\n",
    "# MatMul kernel\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,\n",
    "        stride_bk, stride_bn,\n",
    "        stride_cm, stride_cn,\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        accumulator = tl.dot(a, b, accumulator)\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "# MatMul kernel wrapper function\n",
    "def matmul(a, b):\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel[grid](\n",
    "        a, b, c,\n",
    "        M, N, K,\n",
    "        a.stride(0), a.stride(1),\n",
    "        b.stride(0), b.stride(1),\n",
    "        c.stride(0), c.stride(1),\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test matrices\n",
    "    torch.manual_seed(0)\n",
    "    M = 4096\n",
    "    N = 4096\n",
    "    a = torch.randn((M, N), device='cuda', dtype=torch.float16)\n",
    "    b = torch.randn((N, M), device='cuda', dtype=torch.float16)\n",
    "\n",
    "    # Run the MatMul kernel\n",
    "    triton_output = matmul(a, b)\n",
    "    print(f\"triton_output_with_fp16_inputs={triton_output}\")\n",
    "\n",
    "    # Run the Torch MatMul kernel for comparison\n",
    "    torch_output = torch.matmul(a, b)\n",
    "    print(f\"torch_output_with_fp16_inputs={torch_output}\")\n",
    "\n",
    "    # Verify the Triton kernels results against the Torch kernels\n",
    "    triton.testing.assert_close(triton_output, torch_output, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c786c2a3",
   "metadata": {},
   "source": [
    "## Let's profile the improved kernel with Nsight Compute and generate a report file (improved_matmul.ncu-rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d36f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==PROF== Connected to process 22840 (/usr/bin/python3.12)\n",
      "==PROF== Profiling \"distribution_elementwise_grid...\" - 0: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"distribution_elementwise_grid...\" - 1: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 2: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 3: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 4: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 5: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 6: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 7: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 8: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 9: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 10: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 11: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 12: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 13: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 14: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 15: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 16: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 17: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 18: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 19: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 20: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 21: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 22: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 23: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 24: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 25: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 26: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 27: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 28: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 29: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 30: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 31: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 32: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 33: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 34: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 35: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 36: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 37: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 38: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 39: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 40: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 41: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 42: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 43: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 44: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 45: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 46: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 47: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 48: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 49: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 50: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 51: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 52: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 53: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 54: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 55: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 56: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 57: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 58: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 59: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 60: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 61: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 62: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 63: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 64: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 65: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 66: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 67: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 68: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 69: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 70: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 71: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 72: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 73: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 74: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 75: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 76: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 77: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 78: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 79: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 80: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 81: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 82: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 83: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 84: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 85: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 86: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 87: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 88: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 89: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 90: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 91: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 92: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 93: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 94: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 95: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 96: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 97: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 98: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 99: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 100: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 101: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 102: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 103: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 104: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 105: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 106: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 107: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 108: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 109: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 110: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 111: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 112: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 113: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"matmul_kernel\" - 114: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 115: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 116: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 117: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 118: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 119: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 120: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 121: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 122: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 123: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 124: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 125: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 126: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 127: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceReduceSingleTileKernel\" - 128: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceCompactInitKernel\" - 129: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceSelectSweepKernel\" - 130: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"index_elementwise_kernel\" - 131: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 132: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 133: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 134: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 135: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 136: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 137: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 138: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 139: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 140: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 141: 0%....50%....100% - 40 passes\n",
      "triton_output_with_fp16_inputs=tensor([[ -90.1875,   23.7188,    4.5820,  ...,   45.5312,   99.7500,\n",
      "          -18.7656],\n",
      "        [  50.1562,  -74.5000,    7.1836,  ...,  -65.9375,   12.8828,\n",
      "           11.8906],\n",
      "        [ -70.3750,   73.3125,   16.3438,  ...,   46.4062,   91.8125,\n",
      "           67.3750],\n",
      "        ...,\n",
      "        [-111.3125,  -90.3125,   -7.9844,  ...,   16.4375,   77.3125,\n",
      "          -47.7812],\n",
      "        [  43.5938,   13.3594,  -18.0156,  ...,  -19.0156,    0.4849,\n",
      "          -19.2812],\n",
      "        [  -7.6992,   53.0000,   74.5625,  ...,    4.3945,   17.4375,\n",
      "           30.4531]], device='cuda:0', dtype=torch.float16)\n",
      "==PROF== Profiling \"Kernel2\" - 142: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 143: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 144: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 145: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 146: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 147: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 148: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"CatArrayBatchedCopy_contig\" - 149: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 150: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 151: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 152: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 153: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 154: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 155: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceReduceSingleTileKernel\" - 156: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceCompactInitKernel\" - 157: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"DeviceSelectSweepKernel\" - 158: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"index_elementwise_kernel\" - 159: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 160: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"unrolled_elementwise_kernel\" - 161: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 162: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"reduce_kernel\" - 163: 0%....50%....100% - 39 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 164: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 165: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 166: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 167: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 168: 0%....50%....100% - 40 passes\n",
      "==PROF== Profiling \"vectorized_elementwise_kernel\" - 169: 0%....50%....100% - 40 passes\n",
      "torch_output_with_fp16_inputs=tensor([[ -90.1875,   23.7188,    4.5820,  ...,   45.5312,   99.7500,\n",
      "          -18.7656],\n",
      "        [  50.1562,  -74.5000,    7.1836,  ...,  -65.9375,   12.8828,\n",
      "           11.8906],\n",
      "        [ -70.3750,   73.3125,   16.3438,  ...,   46.4062,   91.8125,\n",
      "           67.3750],\n",
      "        ...,\n",
      "        [-111.3125,  -90.3125,   -7.9844,  ...,   16.4375,   77.3125,\n",
      "          -47.7812],\n",
      "        [  43.5938,   13.3594,  -18.0156,  ...,  -19.0156,    0.4849,\n",
      "          -19.2812],\n",
      "        [  -7.6992,   53.0000,   74.5625,  ...,    4.3945,   17.4375,\n",
      "           30.4531]], device='cuda:0', dtype=torch.float16)\n",
      "==PROF== Disconnected from process 22840\n",
      "==PROF== Report: /workspace/improved_matmul.ncu-rep\n"
     ]
    }
   ],
   "source": [
    "!ncu --target-processes all --set full --import-source on -f -o improved_matmul python3.12 improved_matmul.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
